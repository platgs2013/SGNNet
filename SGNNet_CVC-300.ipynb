{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import imageio\n",
    "import torchvision\n",
    "import py_sod_metrics\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import Module, Parameter, Softmax\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchvision.models import resnet34\n",
    "\n",
    "from sam2.build_sam import build_sam2\n",
    "from dataset import TestDataset,FullDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_str = time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime())\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\" \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiera_path = './sam2_weight/sam2_hiera_large.pt'\n",
    "\n",
    "dataset_name = 'CVC-300'\n",
    "dataset_base = ''\n",
    "\n",
    "train_image_path = os.path.join(dataset_base,'TrainDataset','image/')\n",
    "train_mask_path = os.path.join(dataset_base,'TrainDataset','masks/')\n",
    "test_image_path = os.path.join(dataset_base,'TestDataset',dataset_name,'images/')\n",
    "test_mask_path = os.path.join(dataset_base,'TestDataset',dataset_name,'masks/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes,\n",
    "                              kernel_size=kernel_size, stride=stride,\n",
    "                              padding=padding, dilation=dilation, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_planes)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthWiseConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False):\n",
    "        super(DepthWiseConv2d, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size, stride, padding, dilation, groups=in_channels,\n",
    "                               bias=bias)\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, 1, 1, 0, 1, 1, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"\"\" \n",
    "    LayerNorm that supports two data formats: channels_last (default) or channels_first. \n",
    "    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with \n",
    "    shape (batch_size, height, width, channels) while channels_first corresponds to inputs \n",
    "    with shape (batch_size, channels, height, width).\n",
    "    \"\"\"\n",
    "    def __init__(self, normalized_shape, eps=1e-6, data_format=\"channels_last\"):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(normalized_shape))\n",
    "        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n",
    "        self.eps = eps\n",
    "        self.data_format = data_format\n",
    "        if self.data_format not in [\"channels_last\", \"channels_first\"]:\n",
    "            raise NotImplementedError \n",
    "        self.normalized_shape = (normalized_shape, )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.data_format == \"channels_last\":\n",
    "            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
    "        elif self.data_format == \"channels_first\":\n",
    "            u = x.mean(1, keepdim=True)\n",
    "            s = (x - u).pow(2).mean(1, keepdim=True)\n",
    "            x = (x - u) / torch.sqrt(s + self.eps)\n",
    "            x = self.weight[:, None, None] * x + self.bias[:, None, None]\n",
    "            return x\n",
    "        \n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, dim, kernel_size, expand_ratio=2):\n",
    "        super().__init__()\n",
    "        self.norm = LayerNorm(dim, eps=1e-6, data_format=\"channels_first\")\n",
    "        self.att = nn.Sequential(\n",
    "                nn.Conv2d(dim, dim, 1),\n",
    "                nn.GELU(),\n",
    "                nn.Conv2d(dim, dim, kernel_size=kernel_size, padding=kernel_size//2, groups=dim)\n",
    "        )\n",
    "        self.v = nn.Conv2d(dim, dim, 1)\n",
    "        self.proj = nn.Conv2d(dim, dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        x = self.norm(x)        \n",
    "        x = self.att(x) * self.v(x)\n",
    "        x = self.proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autopad(k, p=None, d=1):  # kernel, padding, dilation\n",
    "    \"\"\"Pad to 'same' shape outputs.\"\"\"\n",
    "    if d > 1:\n",
    "        k = d * (k - 1) + 1 if isinstance(k, int) else [d * (x - 1) + 1 for x in k]  # actual kernel-size\n",
    "    if p is None:\n",
    "        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # auto-pad\n",
    "    return p\n",
    "\n",
    "class Conv(nn.Module):\n",
    "    \"\"\"Standard convolution with args(ch_in, ch_out, kernel, stride, padding, groups, dilation, activation).\"\"\"\n",
    "\n",
    "    default_act = nn.SiLU()  # default activation\n",
    "\n",
    "    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, d=1, act=True):\n",
    "        \"\"\"Initialize Conv layer with given arguments including activation.\"\"\"\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p, d), groups=g, dilation=d, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(c2)\n",
    "        self.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Apply convolution, batch normalization and activation to input tensor.\"\"\"\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "\n",
    "    def forward_fuse(self, x):\n",
    "        \"\"\"Perform transposed convolution of 2D data.\"\"\"\n",
    "        return self.act(self.conv(x))\n",
    "\n",
    "\n",
    "class Pinwheel_shapedConv(nn.Module):  \n",
    "    ''' Pinwheel-shaped Convolution using the Asymmetric Padding method. '''\n",
    "    \n",
    "    def __init__(self, c1, c2, k, s):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.k = k\n",
    "        p = [(k, 0, 1, 0), (0, k, 0, 1), (0, 1, k, 0), (1, 0, 0, k)]\n",
    "        self.pad = [nn.ZeroPad2d(padding=(p[g])) for g in range(4)]\n",
    "        self.cw = Conv(c1, c2 // 4, (1, k), s=s, p=0)\n",
    "        self.ch = Conv(c1, c2 // 4, (k, 1), s=s, p=0)\n",
    "        self.cat = Conv(c2, c2, 2, s=1, p=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        yw0 = self.cw(self.pad[0](x))\n",
    "        yw1 = self.cw(self.pad[1](x))\n",
    "        yh0 = self.ch(self.pad[2](x))\n",
    "        yh1 = self.ch(self.pad[3](x))\n",
    "        return self.cat(torch.cat([yw0, yw1, yh0, yh1], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adapter_linear(nn.Module):\n",
    "    def __init__(self, blk) -> None:\n",
    "        super(Adapter_linear, self).__init__()\n",
    "        self.block = blk\n",
    "        dim = blk.attn.qkv.in_features\n",
    "        self.prompt_learn = nn.Sequential(\n",
    "            nn.Linear(dim, 256),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(256, dim),\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        prompt = self.prompt_learn(x)\n",
    "        promped = x + prompt\n",
    "        net = self.block(promped)\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFB_modified(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(RFB_modified, self).__init__()\n",
    "        self.relu = nn.ReLU(True)\n",
    "        self.branch0 = nn.Sequential(\n",
    "            # CBAM(in_channels=in_channel, ratio=16, kernel_size=7),\n",
    "            BasicConv2d(in_channel, out_channel, 1),\n",
    "        )\n",
    "        self.branch1 = nn.Sequential(\n",
    "            Pinwheel_shapedConv(in_channel,out_channel,k=3,s=1),\n",
    "        )\n",
    "        self.branch2 = nn.Sequential(\n",
    "            Pinwheel_shapedConv(in_channel,out_channel,k=5,s=1),\n",
    "        )\n",
    "        self.branch3 = nn.Sequential(\n",
    "            SpatialAttention(dim=in_channel, kernel_size=3),\n",
    "            BasicConv2d(in_channel, out_channel, 1,),\n",
    "        )\n",
    "        self.conv_cat = BasicConv2d(4*out_channel, out_channel, 3, padding=1)\n",
    "        self.conv_res = BasicConv2d(in_channel, out_channel, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        x_cat = self.conv_cat(torch.cat((x0, x1, x2, x3), 1))\n",
    "\n",
    "        x = self.relu(x_cat + self.conv_res(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAM2UNet(nn.Module):\n",
    "    def __init__(self, checkpoint_path=None) -> None:\n",
    "        super(SAM2UNet, self).__init__()    \n",
    "        model_cfg = \"sam2_hiera_l.yaml\"\n",
    "        if checkpoint_path:\n",
    "            model = build_sam2(model_cfg, checkpoint_path)\n",
    "        else:\n",
    "            model = build_sam2(model_cfg)\n",
    "        del model.sam_mask_decoder\n",
    "        del model.sam_prompt_encoder\n",
    "        del model.memory_encoder\n",
    "        del model.memory_attention\n",
    "        del model.mask_downsample\n",
    "        del model.obj_ptr_tpos_proj\n",
    "        del model.obj_ptr_proj\n",
    "        del model.image_encoder.neck\n",
    "        self.encoder = model.image_encoder.trunk\n",
    "\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        blocks = []\n",
    "        i = 0\n",
    "        for block in self.encoder.blocks:\n",
    "          if i % 2 == 0:\n",
    "              blocks.append(\n",
    "              Adapter_linear(block)\n",
    "              )\n",
    "          else:\n",
    "              blocks.append(block)\n",
    "          i += 1\n",
    "        self.encoder.blocks = nn.Sequential(\n",
    "            *blocks\n",
    "        )\n",
    "        \n",
    "        self.rfb1 = RFB_modified(144, 64)\n",
    "        self.rfb2 = RFB_modified(288, 64)\n",
    "        self.rfb3 = RFB_modified(576, 64)\n",
    "        self.rfb4 = RFB_modified(1152, 64)\n",
    "\n",
    "        self.up1 = (Up(128, 64))\n",
    "        self.up2 = (Up(128, 64))\n",
    "        self.up3 = (Up(128, 64))\n",
    "        self.up4 = (Up(128, 64))\n",
    "        self.side1 = nn.Conv2d(64, 1, kernel_size=1)\n",
    "        self.side2 = nn.Conv2d(64, 1, kernel_size=1)\n",
    "        self.head = nn.Conv2d(64, 1, kernel_size=1)\n",
    "        \n",
    "        self.res1 = nn.Conv2d(144, 64, kernel_size=1)\n",
    "        self.res2 = nn.Conv2d(288, 64, kernel_size=1)\n",
    "        self.res3 = nn.Conv2d(576, 64, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1_res, x2_res, x3_res, x4_res = self.encoder(x)\n",
    "        x1, x2, x3, x4 = self.rfb1(x1_res), self.rfb2(x2_res), self.rfb3(x3_res), self.rfb4(x4_res)\n",
    "        x = self.up1(x4, x3)\n",
    "        x = x * self.res3(x3_res)\n",
    "        out1 = F.interpolate(self.side1(x), scale_factor=16, mode='bilinear')\n",
    "        x = self.up2(x, x2)\n",
    "        x = x * self.res2(x2_res)\n",
    "        out2 = F.interpolate(self.side2(x), scale_factor=8, mode='bilinear')\n",
    "        x = self.up3(x, x1)\n",
    "        x = x * self.res1(x1_res)\n",
    "        out = F.interpolate(self.head(x), scale_factor=4, mode='bilinear')\n",
    "        \n",
    "        return out, out1, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all(model, path):\n",
    "    data_path = path\n",
    "    image_root = '{}/images/'.format(data_path)\n",
    "    gt_root = '{}/masks/'.format(data_path)\n",
    "    model.eval()\n",
    "    num1 = len(os.listdir(gt_root))\n",
    "    test_loader = TestDataset(image_root, gt_root, 512)\n",
    "    \n",
    "    # 初始化三个评估指标\n",
    "    DSC = 0.0\n",
    "    mIOU = 0.0\n",
    "    MAE = 0.0\n",
    "\n",
    "    for i in range(num1):\n",
    "        image, gt,_ = test_loader.load_data()\n",
    "        gt = np.asarray(gt, np.float32)\n",
    "        gt /= (gt.max() + 1e-8)\n",
    "        image = image.cuda()\n",
    "\n",
    "        res, _, _  = model(image)\n",
    "        \n",
    "        # 调整尺寸并归一化\n",
    "        res = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
    "        res = res.sigmoid().data.cpu().numpy().squeeze()\n",
    "        res = (res - res.min()) / (res.max() - res.min() + 1e-8)\n",
    "\n",
    "        # 计算Dice系数\n",
    "        input = res\n",
    "        target = np.array(gt)\n",
    "        smooth = 1\n",
    "        input_flat = input.flatten()\n",
    "        target_flat = target.flatten()\n",
    "        intersection = (input_flat * target_flat).sum()\n",
    "        dice = (2 * intersection + smooth) / (input.sum() + target.sum() + smooth)\n",
    "        DSC += dice\n",
    "\n",
    "        # 计算MAE（不需要阈值）\n",
    "        mae = np.abs(res - gt).mean()\n",
    "        MAE += mae\n",
    "\n",
    "        # 计算mIOU（需要二值化）\n",
    "        threshold = 0.5\n",
    "        pred_binary = (res >= threshold).astype(np.float32)\n",
    "        gt_binary = gt.astype(np.float32)\n",
    "        \n",
    "        intersection = (pred_binary * gt_binary).sum()\n",
    "        union = pred_binary.sum() + gt_binary.sum() - intersection\n",
    "        iou = (intersection + 1e-8) / (union + 1e-8)\n",
    "        mIOU += iou\n",
    "\n",
    "    # 返回三个指标的平均值\n",
    "    return DSC/num1, mIOU/num1, MAE/num1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1856208/259250972.py:23: UserWarning: `nn.functional.upsample` is deprecated. Use `nn.functional.interpolate` instead.\n",
      "  res = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9189201 0.8621931 0.0062314295\n"
     ]
    }
   ],
   "source": [
    "testpath = '/home/mlw/SGN/Nets/datasets/TestDataset/CVC-300'\n",
    "checkpoint = './model/CVC-300/Best_ours_full.pth'\n",
    "model = nn.DataParallel(SAM2UNet(hiera_path).to(device))\n",
    "model = torch.load(checkpoint, map_location=device)\n",
    "model.eval()\n",
    "meandice,meanIOU,meanMAE = test_all(model, testpath)\n",
    "print(meandice,meanIOU,meanMAE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam2-unet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
